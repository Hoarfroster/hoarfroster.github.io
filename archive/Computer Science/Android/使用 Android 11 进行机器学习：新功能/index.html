<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>使用 Android 11 进行机器学习：新功能</title>
    <script src="/assets/script/main.js"></script>
    <link rel="stylesheet" href="/assets/style/styles.css">
</head>

<body>
    <div class="header">
    <div class="container">
        <div class="icon">
            <img src="/assets/media/vectors/hoarfroster-text.svg" alt="Hoarfroster Logo with Text">
        </div>
        <nav class="navigation">
            <ul class="header-navigation-list">
                <li><a href="/">首页</a></li>
                <li><a href="/archive.html">文章</a></li>
                <li><a href="/about.html">关于</a></li>
            </ul>
            <form action="/search" method="post">
                <label>
                    <input type="text" class="search" placeholder="搜索咕咕咕的小站"/>
                </label>
                <label class="submit">
                    <input type="submit"/>
                </label>
            </form>
        </nav>
        <ul class="social-accounts">
            <li>
                <a href="https://www.zhihu.com/people/shuang-yu-29-75">
                    <i class="fa-brands fa-zhihu" style="font-size: 20px; color:#06f; line-height: 20px;"></i>
                </a>
            </li>
            <li>
                <a href="https://github.com/PassionPenguin">
                    <img src="/assets/media/vectors/github.svg" alt="github-logo"/>
                </a>
            </li>
            <li>
                <a href="https://dribbble.com/Hoarfroster">
                    <img src="/assets/media/vectors/dribbble.svg" alt="dribbble-logo"/>
                </a>
            </li>
        </ul>
    </div>
</div>
    <div class="content article">
        <article>
            <div class="title">
                <h1>使用 Android 11 进行机器学习：新功能</h1>
                <p><span class='chars'>15101B</span><span class='created-date'>Created Sat May 28 2022 23:43:08 GM</span><span class='modified-date'>Modified Sat May 28 2022 23:43:08 GM</span></p>
            </div>
            <div class="main markdown-body">
                

<blockquote>
<ul>
<li>原文地址：<a href="https://proandroiddev.com/machine-learning-with-android-11-whats-new-1a8d084c7398">Machine
Learning with Android 11: What’s new</a></li>
<li>原文作者：<a href="https://medium.com/@rishit.dagli">Rishit
Dagli</a></li>
<li>译者：<a href="https://github.com/PassionPenguin">霜羽
Hoarfroster</a></li>
<li>校对者：<a href="https://github.com/HumanBeingXenon">HumanBeing</a>、<a href="https://github.com/keepmovingljzy">keepmovingljzy</a>、<a href="https://github.com/lsvih">lsvih</a></li>
</ul>
</blockquote>
<p><img src="https://cdn-images-1.medium.com/max/3840/1*_6zTCa-SeOV2q549ey3b5Q.jpeg" alt="使用 Android 11 进行机器学习：新功能"></p>
<p>本文将会向大家展示如何使用专为 <a href="https://developer.android.com/11">Android 11</a>
设计的工具或插件来开始使用设备上的 ML（Machine
Learning，机器学习）功能。如果你以前在 Android 中使用过
ML，则可以跟随本文一起探索将你的 ML 应用程序与 Android
应用程序集成的更简便方法。而如果你没有在 Android 中使用过
ML，那么这可能是你使用 Android 进行 ML 的起点，开始你使用 ML 为你的
Android 应用程序提供超强功能之旅。在此博客中，我将主要演示 Android 11
的两个最强大的更新：<a href="https://developer.android.com/studio/preview/features#tensor-flow-lite-models">ML
模型绑定插件</a>和<a href="https://g.co/mlkit">新的 ML Kit
套件</a>。我们下面讨论的所有示例应用程序代码都可以在<a href="https://github.com/Rishit-dagli/ML-with-Android-11">此 GitHub
存储库</a>中找到。</p>
<p>你也可以在 <a href="https://github.com/Rishit-dagli/ML-with-Android-11/blob/master/talks.md">GitHub
存储库</a>中查看有关该主题的讨论。</p>
<h2 id="为什么我们要关心-android-设备上-ml-功能">为什么我们要关心
Android 设备上 ML 功能？</h2>
<p>如你所见，我们在本文中主要关注设备上的 ML。Android 11 对设备上的 ML
做出了许多很酷的更新，但先简述一下我们为什么要对此加以关注。你也将这里知道为什么会有这么多关于
ML 或 终端 ML 的宣传。</p>
<p><strong>设备上的 ML 背后的理念：</strong></p>
<p>这里使用 ML
的方法与我们的旧有方法恰好相反，我们不再将设备上的数据发送到服务器或某个基于云的系统，在上面使用
ML
判断数据，然后再将得出的结论返回给设备。取而代之的是，直接利用设备上的
ML
模型获取输出或推断，即不再让设备发送数据给服务器判断数据，利用移动设备本身，完成所有的处理和推断。</p>
<p><img src="https://cdn-images-1.medium.com/max/3836/1*O1a_Su6P-XggXk9IXTSzMQ.jpeg" alt="设备上 ML 背后的理念"></p>
<p>你不会直接将模型用于你的设备，而需要在导入前先对你的模型进行压缩或优化，以便能够在设备上正常的运行它
——
因为终端设备的计算能力、网络可用性和磁盘空间有限。但在本文中，我们将跳过优化过程，直接部署
<code>.tflite</code> 模型文件。而你可以进一步了解 <a href="https://www.tensorflow.org/lite/">TensorFlow Lite</a>和<a href="https://www.tensorflow.org/lite/performance/model_optimization">模型优化过程</a>。</p>
<p><strong>设备上进行 ML 的优势</strong></p>
<p>使用设备上 ML 的一些优点：</p>
<ul>
<li>能量消耗</li>
</ul>
<p>你所能够想到的第一件事应该就是能耗：曾经你需要耗费大量的能量，将你的视频数据连续发送或流式传输到服务器。但有时这样做是不可行的
——
没有数据网络的时候。值得一提的是，如果你对你的数据先做大量的预处理，倒也能节省些能耗。</p>
<ul>
<li>推理时间</li>
</ul>
<p>另一项要考虑的重要事项是获取输出或实际运行模型所花的时间。对于实时应用而言，这是一个相当重要的层面。程序无需发送或接受数据，加快了推理的速度。</p>
<ul>
<li>网络可用性</li>
</ul>
<p>使用传统方法在考虑网络可用性层面也是相当昂贵的，因为你的设备必须在适宜的带宽或网络环境中，才能连续发送数据并从服务器接收数据才能正常获取
ML 结果。</p>
<ul>
<li>安全</li>
</ul>
<p>最后，你的数据的安全性也将提升：设备不再需要将数据发送到服务器或基于云的系统，即不再将数据发送出设备，从而增强了安全性。</p>
<h2 id="ml-模型绑定插件">ML 模型绑定插件</h2>
<blockquote>
<p>注意：您需要 Android Studio 4.1 或更高版本才能使用 ML
模型绑定插件</p>
</blockquote>
<p><strong>ML 模型绑定插件主要关注什么？</strong></p>
<p>你可以从“模型构建”这个名称中做出足够合理的猜测，从而了解 <a href="https://developer.android.com/studio/preview/features#tensor-flow-lite-models">ML
模型绑定插件</a>。它确实可以使我们非常轻松地使用自定义 TF Lite
模型，让我们这群开发人员可以方便地导入任何 TFLite
模型，读取导入的模型的输入或输出的签名，并且只需要再调用几行代码，就可以使用
TensorFlow Lite Android 支持库。</p>
<p>ML 模型绑定插件使您可以在应用程序中轻松使用 TF
模型。从本质上讲，你需要编写的调用 TensorFlow Lite Android
支持库的代码要少得多。如果你曾经使用过 TensorFlow Lite
模型，则你可能知道你首先需要将所有内容都转换为
<code>ByteArray</code>。使用 ML
模型绑定插件，你将不再需要再将所有内容都转换为
<code>ByteArray</code>。</p>
<p>我喜欢这个新插件的另一个原因是我可以轻松地使用 GPU 和 NN API。使用 ML
模型绑定插件，使用它们从未如此简单。现在，要使用它们，我们仅仅只需要调用一个依赖项和一行代码。难道使用
模型绑定 插件不酷嘛？借助 Android 11 神经网络
API，我们甚至还拥有了无符号整数权重支持和新的服务质量（QOS）API，也同时还支持了更多的终端场景。使用上文谈及的这些功能，你绝对可以更快地进行开发！</p>
<p><strong>使用模型绑定插件</strong></p>
<p>现在让我们看看如何实现所讨论的内容。</p>
<p>因此，第一步是导入带有元数据的 TensorFlow Lite 模型。Android Studio
现在有一个用于导入 TensorFlow
模型的新选项：只需右键单击要导入它的模块，随后你将会在
<code>Others</code> 下看到一个叫 <code>TF Lite Model</code> 的选项。</p>
<p><img src="https://cdn-images-1.medium.com/max/2500/1*fnNNyLYKqafERAjUfwPsxQ.jpeg" alt="Android Studio 中的导入模型选项"></p>
<p>我们只需传递 <code>tflite</code>
模型的路径即可，而它就会自动地在你之前选择的 <code>ml</code>
模块中的目录中为我们导入模型。我们现在就可以在其中使用该模型，并且我们只需几个单击即可添加依赖项目和使用
GPU 加速。</p>
<p><img src="https://cdn-images-1.medium.com/max/2502/1*wJmnVf7wtCOV50HnXXmmPQ.jpeg" alt="导入 tflite 模型"></p>
<p>现在从我的模型元数据中，我还可以知道输入、输出的类型以及其他需要被使用的信息
—— 我们可以通过在 Android Studio 中打开 <code>tflite</code>
模型文件来查看此信息。在这个屏幕截图中，我使用的是我制作的开源模型来对剪刀、石头、布进行区分。我们只需将手放在摄像头前即可识别出是剪刀还是石头还是布，这也是我在本文中演示的内容。</p>
<p><img src="https://cdn-images-1.medium.com/max/2502/1*ZHuSORcTLhxtSWr60TzxWA.jpeg" alt="查看模型元数据"></p>
<p>最后，让我们开始使用该模型，以便进行流推断，这很可能也是你想要执行的操作：实时图像分类。要实现这个，最简单的方法是使用
Camera
X，并将每个帧传递给可以执行推理的函数。在这里，其实我感兴趣的是进行推断的函数。我们可以发现执行此操作真的是非常容易：在导入可以使用的
TF Lite 模型时，似乎也同时生成了一份示例代码。</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="kw">val</span> <span class="va">rpsModel</span> <span class="op">=</span> RPSModel<span class="op">.</span>newInstance<span class="op">(</span>ctx<span class="op">)</span></span></code></pre></div>
<p>这里我们将首先实例化一个 <code>rps</code>
模型，该模型是剪刀石头布模型的缩写，并将其传递给上下文。在使用这个插件，同时我的模型名称为
<code>RPS Model.tflite</code>
的情况下，程序为我创建了一个完全相同名称的类，一个名为
<code>RPS Model</code> 的类。</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> <span class="va">tfImage</span> <span class="op">=</span> TensorImage<span class="op">.</span>fromBitmap<span class="op">(</span>toBitmap<span class="op">(</span>imageProxy<span class="op">))</span></span></code></pre></div>
<p>现在我们需要将数据转换为可使用的格式，以便将其从 <code>Bitmap</code>
转换为 <code>Tensor Image</code>。如果我们使用 TF
解释器，则我们需要将图像转换为一个<code>ByteArray</code>。但现在我们无需再这样做了
—— 直接交给一个图片代理去处理即可。</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">val</span> <span class="va">outputs</span> <span class="op">=</span> rpsModel<span class="op">.</span>process<span class="op">(</span>tfImage<span class="op">)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>probabilityAsCategoryList<span class="op">.</span>apply <span class="op">{</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        sortByDescending <span class="op">{</span> it<span class="op">.</span>score <span class="op">}</span> <span class="co">// 排序，高匹配率优先</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">}.</span>take<span class="op">(</span>MAX_RESULT_DISPLAY<span class="op">)</span> <span class="co">// 抱走第一</span></span></code></pre></div>
<p>现在我们已经将数据传递给模型，我们将处理模型中的图像并获得输出，我们将基本上得到一个匹配率的数组并对其进行降序排序，以获取具有最大值的概率，然后选择降序列表的第一名显示出来。</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> <span class="op">(</span>output <span class="kw">in</span> outputs<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    items<span class="op">.</span>add<span class="op">(</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        Recognition<span class="op">(</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>            output<span class="op">.</span>label<span class="op">,</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>            output<span class="op">.</span>score</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="op">)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="op">)</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>最后，我需要向用户显示标签，因此我将在输出中添加与每个条目相对应的标签。这就是我们所需要的全部代码！
🚀～</p>
<p><strong>使用 GPU 加速</strong></p>
<p>如果我们想要使用 GPU 加速，其实做法非常简单。我们只需要在要使用 GPU
并进行构建模型的地方创建一个 <code>options</code>
对象。我只是将其作为参数传递给实例化过程。我们现在就可以使用
GPU，这个简易操作让使用 NN API 加速并在 Android 11
上执行更多操作变得非常容易。</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="kw">val</span> <span class="va">options</span> <span class="op">=</span> Model<span class="op">.</span>Options<span class="op">.</span>Builder<span class="op">().</span>setDevice<span class="op">(</span>Model<span class="op">.</span>Device<span class="op">.</span>GPU<span class="op">).</span>build<span class="op">()</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="kw">val</span> <span class="va">rpsModel</span> <span class="op">=</span> rpsModel<span class="op">.</span>newInstance<span class="op">(</span>ctx<span class="op">,</span> options<span class="op">)</span></span></code></pre></div>
<h2 id="一个新的-ml-kit-套件">一个新的 ML Kit 套件</h2>
<blockquote>
<p>我们现在不再需要 Firebase 项目来与 ML Kit
一起使用，虽然说我们依旧可以在 Firebase 中使用它。</p>
</blockquote>
<p>另一个值得注意的更新是可以通过 <a href="https://g.co/mlkit">ML
Kit</a> 使用 TensorFlow Lite 模型。而且即使我们不使用 Firebase
项目，我们现在也可以直接使用 ML Kit 了。</p>
<p>正如我之前提到的，由于我之前提到的好处，Android 11
中有许多更新集中在设备上的 ML 上。现在，新的 ML Kit
在设备上具有更好的可用性。ML Kit 的<a href="https://developers.google.com/ml-kit/vision/image-labeling/custom-models/android">图像分类</a>和<a href="https://developers.google.com/ml-kit/vision/object-detection/custom-models/android">对象检测和跟踪（ODT）</a>现在也支持自定义模型，这意味着我们可以使用
<code>tflite</code> 模型文件走遍 Android 的 ML
了。这也意味着如果我们正在处理某些常见场景，例如对特定类型的对象检测，那么
ML Kit 是最好的选择。</p>
<p><strong>使用 ML Kit</strong></p>
<p>让我们在代码中看看如何做到这一点～我们现在将要建立一个可以对不同食品分类的模型，</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> localModel <span class="op">=</span> LocalModel<span class="op">.</span>Builder<span class="op">()</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>setAssetFilePath<span class="op">(</span><span class="st">"lite-model_aiy_vision_classifier_food_V1_1.tflite"</span><span class="op">).</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>build<span class="op">()</span></span></code></pre></div>
<p>在这里我将首先通过设置模型并为其指定 <code>tflite</code>
模型文件路径开始。</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="kw">val</span> <span class="va">customObjectDetectorOptions</span> <span class="op">=</span> CustomObjectDetectorOptions</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>Builder<span class="op">(</span>localModel<span class="op">)</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>setDetectorMode<span class="op">(</span>CustomObjectDetectorOptions<span class="op">.</span>STREAM_MODE<span class="op">)</span> </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>setClassificationConfidenceThreshold<span class="op">(</span><span class="fl">0.8f</span><span class="op">)</span> </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>build<span class="op">()</span></span></code></pre></div>
<p>然后，此 <code>tflite</code> 模型将在带有 ML Kit
的对象检测模型的顶部运行。我们现在可以稍微自定义这些选项。在这里，由于要使用流输入并指定置信度阈值，因此我专门设置了
<code>STREAM_MODE</code>。</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode kotlin"><code class="sourceCode kotlin"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">private</span> <span class="kw">val</span> <span class="va">objectDetector</span> <span class="op">=</span> ObjectDetection<span class="op">.</span>getClient<span class="op">(</span>customObjectDetectorOptions<span class="op">)</span> objectDetector<span class="op">.</span>process<span class="op">(</span>image<span class="op">)</span> </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>addOnFailureListener<span class="op">(</span>Log<span class="op">.</span>d<span class="op">(...))</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>addOnSuccessListener<span class="op">{</span> </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        graphicsOverlay<span class="op">.</span>clear<span class="op">()</span> </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">(</span>detectedObject <span class="kw">in</span> it<span class="op">){</span> </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>            graphicsOverlay<span class="op">.</span>add<span class="op">(</span>ObjectGraphic<span class="op">(</span>graphicsOverlay<span class="op">,</span> detectedObject<span class="op">))</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="op">}</span> </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        graphicsOverlay<span class="op">.</span>postInvalidate<span class="op">()}</span> </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="op">.</span>addOnCompleteListenerl imageProxy<span class="op">.</span>close<span class="op">()</span> <span class="op">}</span></span></code></pre></div>
<p>让我们进入运行模型的那一部分，这样我们可能会看到一些类似于此处前面示例的语法。我将处理我的图像，这里需要注意的是，所有处于失败或成功状态的侦听器都是必不可缺的代码，在我们的每次运行上都需要附加上这些侦听器。这就是我们所有需要编写的代码！我们已经搞定了！🚀～</p>
<h2 id="查找模型">查找模型</h2>
<p>我们讨论了很多有关模型制作后的内容，让我们看看如何为您的用例找到模型。</p>
<ul>
<li>TF Lite Model Maker</li>
</ul>
<p>TensorFlow 团队也于 2020 年初开启了 TF Lite Model
Maker。这使得制作好的模型超级容易使用，具有很高的性能，还可以进行大量的自定义。我们现在可以简单地传递数据并使用很少的代码来构建
<code>tflite</code> 模型。我们可以查看官网中的 <a href="https://github.com/Rishit-dagli/ML-with-Android-11/blob/dev/TensorFlow_Lite_Model_Maker_example.ipynb">TensorFlow
Lite Model Maker 示例</a>。</p>
<ul>
<li>TensorFlow Hub</li>
</ul>
<p>TensorFlow Hub
是一个开放源代码存储库，其中包含最新技术和有据可查的模型。我们使用 ML
Kit 构建的食品分类应用程序也出现在 TF Hub 上。我们还可以使用<a href="https://tfhub.dev/">社区 tfhub.dev</a> 中的模型。</p>
<p><img src="https://cdn-images-1.medium.com/max/2022/0*cv-fzgw2WPuf4PQI.png" alt="tfhub.dev 上的一些发布者"></p>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*Cu-XiVrzOi2MdKatQ1dpzw.png" alt="TF Hub 中的过滤器"></p>
<p>如果你只想查找基于图像或文本的模型，则可以在 TF Hub
中通过添加过滤条件来搜索。例如如果我们要在网络、终端设备或 Corals 上运行
ML，请通过架构、使用的数据集等筛选等等。</p>
<p>我们可以进一步直接从 TF Hub
下载这些模型，也可以非常轻松地使用您自己的数据对这些模型进行迁移学习。但是，在本文中我们将不进一步介绍使用
TF Hub 的迁移学习了。有关 TF Hub 的更多信息，请前往<a href="https://towardsdatascience.com/building-better-ai-apps-with-tf-hub-88716b302265">我的博客</a>查看。</p>
<p>除此之外，还有不少的服务提供商，例如 <a href="https://teachablemachine.withgoogle.com/">Teachable
Machine</a>，<a href="https://cloud.google.com/automl">AutoML</a>，但上述的都算是比较常见的提供商。</p>
<hr>
<p><a href="https://github.com/Rishit-dagli/ML-with-Android-11">GitHub
仓库</a> 中提供了此处展示的所有有关 TF Lite Model Maker
的示例的代码。我还为您你供了一些已训练的模型，供初学者入门和实验。</p>



            </div>
        </article>
        <div class="sidebar">
            <div class="about-box">
    <div class="avatar">
        <img src="/assets/media/bitmap/avatar.jpeg" alt="avatar">
    </div>
    <h1>霜羽 Hoarfroster</h1>
    <h2>@PassionPenguin</h2>
    <p class="moment"><span class="status">🤔</span><span>努力！</span></p>
    <ul>
        <li><i class="fa-solid fa-location-dot"></i> 广东 · 广州 | <span class="light">Guangzhou, China</span>
        </li>
        <li><i class="fa-solid fa-envelope"></i> <a href="mailto:hoarfroster@outlook.com">hoarfroster@outlook.com</a>
        </li>
        <li><i class="fa-solid fa-house"></i> <a href="https://story.hoarfroster.space/">https://story.hoarfroster.space/</a>
        </li>
    </ul>
</div>
<div class="organization">
    <h4>组织 Organizations</h4>
    <ul>
        <li>
            <img src="https://avatars.githubusercontent.com/u/81648011?s=60&amp;v=4"
                alt="Hexa-Penguin"><span>Hexa-Penguin</span>
        </li>
        <li>
            <img src="https://avatars.githubusercontent.com/u/10482599?s=60&amp;v=4" alt="xitu"><span>稀土 xitu</span>
        </li>
    </ul>
</div>
<div class="category">
    <span class="title">文章分类</span>
    <ul>
        <!-- <li><a href="/archive.html">所有分类</a></li> -->
    </ul>
</div>
<div class="archive">
    <span class="title">文章存档</span>
    <ul>
        <!-- <li><a href="/archive.html">所有文章</a></li> -->
    </ul>
</div>
        </div>
    </div>
    <div class="footer">
    <div class="content">
        <div class="about">
            <p>霜羽 Hoarfroster</p>
            <p>&copy; Copyright 2021 Hoarfroster and contributors.</p>
        </div>
        <div class="nav">
            <div class="links">
                <span class="title">关于文章</span>
                <ul>
                    <li><a href="/archive.html">文章存档</a></li>
                </ul>
            </div>
            <div class="category">
                <span class="title">关于霜羽</span>
                <ul>
                    <li><a href="/about.html">有关霜羽</a></li>
                </ul>
            </div>
        </div>
    </div>
    <ul class="social-accounts">
        <li>
            <a href="https://www.zhihu.com/people/shuang-yu-29-75">
                <i class="fa-brands fa-zhihu" style="font-size: 24px; color:#06f; line-height: 24px;"></i>
            </a>
        </li>
        <li>
            <a href="https://github.com/PassionPenguin">
                <img src="/assets/media/vectors/github.svg" alt="github-logo"/>
            </a>
        </li>
        <li>
            <a href="https://dribbble.com/Hoarfroster">
                <img src="/assets/media/vectors/dribbble.svg" alt="dribbble-logo"/>
            </a>
        </li>
        <li>
            <a href="https://zh.wikipedia.org/wiki/User:HoarfrostFeather">
                <i class="fa-brands fa-wikipedia-w" style="font-size: 22px; color: #888; line-height: 24px;"></i>
            </a>
        </li>
        <li>
            <a href="https://space.bilibili.com/201469972">
                <i class="fa-brands fa-bilibili" style="font-size: 22px; color: #00a1d6; line-height: 24px;"></i>
            </a>
        </li>
    </ul>
</div>
</body>

</html>